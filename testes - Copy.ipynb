{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "import pandas as pd\n",
    "from pandas import Series\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, LSTM, CuDNNLSTM\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "import tensorflow as tf"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "csv_path = 'inp/IBIRITE (ROLA MOCA)_MG.csv'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = pd.read_csv(csv_path, sep=';')\n",
    "data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.rename(columns={\"PRECIPITAÇÃO TOTAL, HORÁRIO (mm)\": \"Chuva\",\n",
    "                     \"PRESSAO ATMOSFERICA AO NIVEL DA ESTACAO, HORARIA (mB)\": \"$Pressão_{Inst}$\",\n",
    "                     \"PRESSÃO ATMOSFERICA MAX.NA HORA ANT. (AUT) (mB)\": \"$Pressão_{Max}$\",\n",
    "                     \"PRESSÃO ATMOSFERICA MIN. NA HORA ANT. (AUT) (mB)\": \"$Pressão_{Min}$\",\n",
    "                     \"RADIACAO GLOBAL (KJ/m²)\": \"H\",\n",
    "                     \"TEMPERATURA DO AR - BULBO SECO, HORARIA (°C)\": \"$Temperatura_{Inst}$\",\n",
    "                     \"TEMPERATURA DO PONTO DE ORVALHO (°C)\": \"$Orvalho_{Inst}$\",\n",
    "                     \"TEMPERATURA MÁXIMA NA HORA ANT. (AUT) (°C)\": \"$Temperatura_{Max}$\",\n",
    "                     \"TEMPERATURA MÍNIMA NA HORA ANT. (AUT) (°C)\": \"$Temperatura_{Min}$\",\n",
    "                     \"TEMPERATURA ORVALHO MAX. NA HORA ANT. (AUT) (°C)\": \"$Orvalho_{Max}$\",\n",
    "                     \"TEMPERATURA ORVALHO MIN. NA HORA ANT. (AUT) (°C)\": \"$Orvalho_{Min}$\",\n",
    "                     \"UMIDADE REL. MAX. NA HORA ANT. (AUT) (%)\": \"$Umidade_{Max}$\",\n",
    "                     \"UMIDADE REL. MIN. NA HORA ANT. (AUT) (%)\": \"$Umidade_{Min}$\",\n",
    "                     \"UMIDADE RELATIVA DO AR, HORARIA (%)\": \"$Umidade_{Inst}$\",\n",
    "                     \"VENTO, DIREÇÃO HORARIA (gr) (° (gr))\": \"$Vento_{Dir}$\",\n",
    "                     \"VENTO, RAJADA MAXIMA (m/s)\": \"$Vento_{Raj}$\",\n",
    "                     \"VENTO, VELOCIDADE HORARIA (m/s)\": \"$Vento_{Vel}$\",\n",
    "                     \"RADIACAO GLOBAL (Kj/m²)\": \"GLOBAL\"}, inplace=True)\n",
    "data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.set_index('DATE', inplace=True)\n",
    "data.dropna(axis=0, how='all', subset=None, inplace=True)\n",
    "data.dropna(axis=1, how='all', subset=None, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#DEPENDENDO DO ANO E DA ESTAÇÃO OS VALORES DE RADIAÇÃO ESTÃO EM COLUNAS DIFERENTES\n",
    "if 'GLOBAL' not in data.columns:\n",
    "    data.rename(columns={\"H\": \"GLOBAL\"}, inplace=True)\n",
    "if 'H' in data.columns:\n",
    "    data['GLOBAL'].fillna(data['H'], inplace=True)\n",
    "    data.drop(['H'], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_dates = pd.to_datetime(data.index)\n",
    "data = data[\n",
    "    ['$Temperatura_{Inst}$', '$Temperatura_{Max}$', '$Temperatura_{Min}$', '$Umidade_{Max}$', '$Umidade_{Min}$',\n",
    "     '$Umidade_{Inst}$', 'GLOBAL']]\n",
    "\n",
    "cols = list(data)[0:7]\n",
    "data = data[cols].astype(float)\n",
    "data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# GARANTINDO QUE TODOS OS DADOS ESTÃO SENDO TRATADOS COMO FLOAT\n",
    "data = data.replace(',', '.', regex=True)\n",
    "data['$Temperatura_{Inst}$'] = data['$Temperatura_{Inst}$'].astype(float)\n",
    "data['$Temperatura_{Max}$'] = data['$Temperatura_{Max}$'].astype(float)\n",
    "data['$Temperatura_{Min}$'] = data['$Temperatura_{Min}$'].astype(float)\n",
    "data['GLOBAL'] = data['GLOBAL'].astype(float)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#DELETANDO ALGUMA LEITURA ONDE O MÁXIMO É MENOR QUE O MÍNIMO\n",
    "delIndex = data.loc[(data['$Temperatura_{Max}$'] < data['$Temperatura_{Min}$']) | (\n",
    "        data['$Umidade_{Max}$'] < data['$Umidade_{Min}$'])].index\n",
    "if len(delIndex) > 0:\n",
    "    data.drop(delIndex, axis=0, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#DELETANDO ALGUMA LEITURA ONDE O MÁXIMO É MENOR QUE O INSTANTÂNEO\n",
    "delIndex = data.loc[(data['$Temperatura_{Max}$'] < data['$Temperatura_{Inst}$']) | (\n",
    "        data['$Umidade_{Max}$'] < data['$Umidade_{Inst}$'])].index\n",
    "if len(delIndex) > 0:\n",
    "    data.drop(delIndex, axis=0, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#DELETANDO ALGUMA LEITURA ONDE O INSTANTÂNEO É MENOR QUE O MÍNIMO\n",
    "delIndex = data.loc[(data['$Temperatura_{Inst}$'] < data['$Temperatura_{Min}$']) | (\n",
    "        data['$Umidade_{Inst}$'] < data['$Umidade_{Min}$'])].index\n",
    "if len(delIndex) > 0:\n",
    "    data.drop(delIndex, axis=0, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# #MODIFICANDO A UNIDADE DA RADIAÇÃO DE (Kj/m²) PARA (Mj/m²)\n",
    "data['GLOBAL'] = data['GLOBAL'].mul(0.001)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#DELETANDO ALGUMA LINHA QUE AINDA TENHA NAN\n",
    "data.dropna(inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# EXTRAINDO OS NOMES DAS COLUNAS\n",
    "target_names = ['GLOBAL']\n",
    "variable_names = data.columns.values\n",
    "variable_names = np.delete(variable_names, np.where(variable_names == target_names))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "date_range = data.index\n",
    "\n",
    "var_to_plot = data.columns\n",
    "df = data[var_to_plot]\n",
    "\n",
    "n = int(df.shape[0] * 0.7)\n",
    "df.index = range(df.shape[0])\n",
    "id0 = df.index <= n\n",
    "id1 = df.index > n\n",
    "print(data.index)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = data[variable_names]\n",
    "y = data[target_names]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# normalizing the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "data = scaler.fit_transform(data)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(X)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x = []\n",
    "train_y = []\n",
    "\n",
    "n_future = 1\n",
    "n_past = 3\n",
    "\n",
    "for i in range(n_past, len(data) - n_future + 1):\n",
    "    train_x.append(data[i - n_past:i, 0:data.shape[1]])\n",
    "    train_y.append(data[i + n_future - 1:i + n_future, 0])\n",
    "\n",
    "train_x = np.array(train_x)\n",
    "train_y = np.array(train_y)\n",
    "\n",
    "# Separar os dados em conjuntos de treinamento e teste\n",
    "test_size = 0.15\n",
    "split_index = int(len(train_x) * (1 - test_size))\n",
    "\n",
    "train_x, test_x = train_x[:split_index], train_x[split_index:]\n",
    "train_y, test_y = train_y[:split_index], train_y[split_index:]\n",
    "\n",
    "\n",
    "print(\"Shape de train_x:\", train_x.shape)\n",
    "print(\"Shape de train_y:\", train_y.shape)\n",
    "print(\"Shape de test_x:\", test_x.shape)\n",
    "print(\"Shape de test_y:\", test_y.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from evolutionary_search import EvolutionaryAlgorithmSearchCV\n",
    "\n",
    "params = {\n",
    "    'batch_size': [2048],\n",
    "    'epochs': [100, 200],\n",
    "    'optimizer': ['adam', 'sgd'],\n",
    "    'learning_rate': [0.01, 0.001],\n",
    "    'activation': ['relu', 'leaky_relu', 'segmoid'],\n",
    "    'dropout': [0.1, 0.2],\n",
    "    'neurons': [32, 64]\n",
    "}\n",
    "\n",
    "\n",
    "def create_model(learning_rate=0.1, optimizer='adam', activation='relu', dropout=0.1, neurons=1):\n",
    "    model1 = Sequential()\n",
    "    model1.add(CuDNNLSTM(neurons, input_shape=(train_x.shape[1], train_x.shape[2]), return_sequences=True))\n",
    "    model1.add(CuDNNLSTM(int(neurons/2), return_sequences=False))\n",
    "    model1.add(Dense(train_y.shape[1]))\n",
    "    model1.add(Dropout(dropout))\n",
    "    if optimizer == 'adam':\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'sgd':\n",
    "        optimizer = SGD(learning_rate=learning_rate)\n",
    "    model1.compile(loss=MeanSquaredError(), optimizer=optimizer,\n",
    "                   metrics=[RootMeanSquaredError()])\n",
    "    return model1\n",
    "\n",
    "\n",
    "model = KerasRegressor(model=create_model, verbose=2, learning_rate=[0.01, 0.001], activation=['relu', 'leaky_relu', 'segmoid'],\n",
    "                       dropout=[0.2, 0.4], neurons=[16, 32, 64])\n",
    "\n",
    "checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "eas = EvolutionaryAlgorithmSearchCV(estimator=model,\n",
    "                                    params=params,\n",
    "                                    scoring='neg_mean_squared_error',\n",
    "                                    cv=3,\n",
    "                                    verbose=1,\n",
    "                                    population_size=50,\n",
    "                                    gene_mutation_prob=0.01,\n",
    "                                    gene_crossover_prob=0.8,\n",
    "                                    tournament_size=3,\n",
    "                                    generations_number=15)\n",
    "\n",
    "# Enable graph execution mode\n",
    "tf.config.run_functions_eagerly(True)\n",
    "# tf.config.run_functions_eagerly(False)\n",
    "\n",
    "# Fit the model\n",
    "eas.fit(train_x, train_y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(eas.best_score_, eas.best_params_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions = eas.predict(test_x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error, max_error, median_absolute_error, mean_squared_log_error, explained_variance_score\n",
    "\n",
    "mse = mean_squared_error(test_y, predictions)\n",
    "r2 = r2_score(test_y, predictions)\n",
    "mae = mean_absolute_error(test_y, predictions)\n",
    "mape = mean_absolute_percentage_error(test_y, predictions)\n",
    "me = max_error(test_y, predictions)\n",
    "medae = median_absolute_error(test_y, predictions)\n",
    "msle = mean_squared_log_error(test_y, predictions)\n",
    "evs = explained_variance_score(test_y, predictions)\n",
    "\n",
    "print('MSE: ', mse, '\\nR2: ', r2, '\\nMAE: ', mae, '\\nMAPE: ', mape, '\\nME: ', me, '\\nMEDAE: ', medae, '\\nMSLE: ', msle, '\\nEVS: ', evs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# inverte a escala para os valores originais\n",
    "predictions_copies = np.repeat(predictions, train_x.shape[2], axis=-1)\n",
    "original = scaler.inverse_transform(predictions_copies)[:,0]\n",
    "print(original)\n",
    "\n",
    "test_y_copies = np.repeat(test_y, train_x.shape[2], axis=-1)\n",
    "original_test = scaler.inverse_transform(test_y_copies)[:,0]\n",
    "print(original_test)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(train_dates.shape)\n",
    "print(original.shape)\n",
    "print(original_test.shape)\n",
    "\n",
    "# Plotar os resultados\n",
    "pl.plot(original, label='Predição')\n",
    "pl.plot(original_test, label='Dados Originais')\n",
    "pl.legend()\n",
    "pl.xlabel('Índice')\n",
    "pl.ylabel('Valor')\n",
    "pl.title('Dados Predição vs. Dados de Teste')\n",
    "pl.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
